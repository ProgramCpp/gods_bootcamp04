{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Clustering via $k$-means***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering** is one of many unsupervised learning methods. In this lab, we'll consider the following form of the clustering task. Suppose you are given\n",
    "\n",
    "* a set of observations,  $X≡\\{\\hat{x}_i|0≤i<n\\}$ , and\n",
    "* a target number of clusters,  $k$.\n",
    "\n",
    "Your goal is to partition the points into $k$ subsets, $C_0,…,C_{k−1}⊆X$, which are\n",
    "\n",
    "* disjoint, i.e.,  $i≠j⟹C_i∩C_j=∅$ ;\n",
    "* but also complete, i.e.,  $C_0∪C_1∪⋯∪C_{k−1}=X$.\n",
    "\n",
    "Intuitively, each cluster should reflect some \"sensible\" grouping. Thus, we need to specify what constitutes such a grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Data\n",
    "import numpy as np\n",
    "DATA_PATH = 'materials/'\n",
    "s1 = 'session_1/'\n",
    "s2 = 'session_2/'\n",
    "\n",
    "data = f'{DATA_PATH}{s1}sessionone_data.csv'\n",
    "\n",
    "compute_d2_test_data = np.load(f'{DATA_PATH}{s1}compute_d2_test_data.npy')\n",
    "compute_d2_test_soln = np.load(f'{DATA_PATH}{s1}compute_d2_test_soln.npy')\n",
    "\n",
    "assign_cluster_test_data = np.load(f'{DATA_PATH}{s1}assign_cluster_test_data.npy')\n",
    "assign_cluster_test_soln = np.load(f'{DATA_PATH}{s1}assign_cluster_test_soln.npy')\n",
    "\n",
    "update_centers_test_data = np.load(f'{DATA_PATH}{s1}update_centers_test_data.npy')\n",
    "update_centers_test_soln = np.load(f'{DATA_PATH}{s1}update_centers_test_soln.npy')\n",
    "\n",
    "img = f\"{DATA_PATH}{s2}tiger.bmp\"###sitting_girl.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The standard $k$ -means algorithm\n",
    "Finding the global optimum is [NP-hard](https://en.wikipedia.org/wiki/NP-hardness), which is computer science mumbo jumbo for \"we don't know whether there is an algorithm to calculate the exact answer in fewer steps than exponential in the size of the input.\" Nevertheless, there is an iterative method, Lloyd’s algorithm, that can quickly converge to a local (as opposed to global) minimum. The procedure alternates between two operations: assignment and update.\n",
    "\n",
    "* **Step 1:** Assignment. Given a fixed set of $k$ centers, assign each point to the nearest center:\n",
    "<center>$C_i= \\{\\hat{x} :∥\\hat{x}−μ_i∥≤∥\\hat{x}−μ_j∥,1≤j≤k\\}$</center>\n",
    "<br>\n",
    "\n",
    "* **Step 2:** Update. Recompute the $k$ centers (\"centroids\") by averaging all the data points belonging to each cluster, i.e., taking their mean:\n",
    "<center>$μ_i=\\frac{1}{|C_i|}\\sum_{\\hat{x}∈C_i} \\hat{x}$</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://stanford.edu/~cpiech/cs221/img/kmeansViz.png\", width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code that follows, it will be convenient to use our usual \"data matrix\" convention, that is, each row of a data matrix $X$ is one of $m$ observations and each column (coordinate) is one of  d  predictors. However, we will not need a dummy column of ones since we are not fitting a function.\n",
    "\n",
    "<center>$X≡ \\begin{pmatrix}\\hat{x}^{T}_0 \\\\⋮ \\\\ \\hat{x}^{T}_m \\end{pmatrix} =(x_0⋯x_{d−1})$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from materials.helper_function.helper_function import count_matches,make_scatter_plot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rc(\"savefig\", dpi=100) # Adjust for higher-resolution figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_scatter_plot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the data points as a data matrix, points, and the labels as a vector, labels. Note that the k-means algorithm you will implement should **not** reference labels -- that's the solution we will try to predict given only the point coordinates (points) and target number of clusters (k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = df[['x_1', 'x_2']].values\n",
    "labels = df['label'].values\n",
    "n, d = points.shape\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labels should not be used in the  k -means algorithm. We use them here only as ground truth for later verification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **How to start? Initializing the $k$ centers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the algorithm, you need an initial guess. Let's randomly choose $k$ observations from the data.\n",
    "\n",
    "**Exercise 1**. Complete the following function, init_centers($X$, $k$), so that it randomly selects $k$ of the given observations to serve as centers. It should return a Numpy array of size k-by-d, where d is the number of columns of $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_centers(X, k):\n",
    "    \"\"\"\n",
    "    Randomly samples k observations from X as centers.\n",
    "    Returns these centers as a (k x d) numpy array.\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `init_centers_test`\n",
    "\n",
    "centers_initial = init_centers(points, k)\n",
    "print(\"Initial centers:\\n\", centers_initial)\n",
    "\n",
    "assert type(centers_initial) is np.ndarray, \"Your function should return a Numpy array instead of a {}\".format(type(centers_initial))\n",
    "assert centers_initial.shape == (k, d), \"Returned centers do not have the right shape ({} x {})\".format(k, d)\n",
    "assert (sum(centers_initial[0, :] == points) == [1, 1]).all(), \"The centers must come from the input.\"\n",
    "assert (sum(centers_initial[1, :] == points) == [1, 1]).all(), \"The centers must come from the input.\"\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Computing the distances**\n",
    "**Exercise 2**. Implement a function that computes a distance matrix, $S=(s_{ij})$  such that $s_{ij}=d_{ij}^2$ is the squared distance from point $x^i$ to center $μ_j$. It should return a Numpy matrix S[:m, :k]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_d2(X, centers):\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `compute_d2_test`\n",
    "\n",
    "S = compute_d2 (points, compute_d2_test_data)\n",
    "assert (np.linalg.norm (S - compute_d2_test_soln, axis=1) <= (20.0 * np.finfo(float).eps)).all()\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**. Write a function that uses the (squared) distance matrix to assign a \"cluster label\" to each point.\n",
    "\n",
    "That is, consider the $m×k$ squared distance matrix $S$. For each point $i$, if $s_{i,j}$ is the minimum squared distance for point $i$, then the index $j$ is $i$'s cluster label. In other words, your function should return a (column) vector $y$ of length $m$ such that\n",
    "\n",
    "\\begin{equation*}\n",
    "y_i=argmin(s_{ij}), \n",
    "j∈{0,…,k−1}.\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cluster_labels(S):\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    ### END SOLUTION\n",
    "\n",
    "# Cluster labels:     0    1\n",
    "S_test1 = np.array([[0.3, 0.2],  # --> cluster 1\n",
    "                    [0.1, 0.5],  # --> cluster 0\n",
    "                    [0.4, 0.2]]) # --> cluster 1\n",
    "y_test1 = assign_cluster_labels(S_test1)\n",
    "print(\"You found:\", y_test1)\n",
    "\n",
    "assert (y_test1 == np.array([1, 0, 1])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `assign_cluster_labels_test`\n",
    "\n",
    "y_test2 = assign_cluster_labels(assign_cluster_test_data)\n",
    "assert (y_test2 == assign_cluster_test_soln).all()\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**. Given a clustering (i.e., a set of points and assignment of labels), compute the center of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_centers(X, y):\n",
    "    # X[:m, :d] == m points, each of dimension d\n",
    "    # y[:m] == cluster labels\n",
    "    m, d = X.shape\n",
    "    k = max(y) + 1\n",
    "    assert m == len(y)\n",
    "    assert (min(y) >= 0)\n",
    "    \n",
    "    centers = np.empty((k, d))\n",
    "    for j in range(k):\n",
    "        # Compute the new center of cluster j,\n",
    "        # i.e., centers[j, :d].\n",
    "        ### BEGIN SOLUTION\n",
    "        centers[j, :d] = np.mean(X[y == j, :], axis=0)\n",
    "        ### END SOLUTION\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `update_centers_test`\n",
    "\n",
    "centers_test3 = update_centers(points, update_centers_test_data)\n",
    "\n",
    "delta_test3 = np.abs(centers_test3 - update_centers_test_soln)\n",
    "assert (delta_test3 <= 2.0*len(update_centers_test_soln)*np.finfo(float).eps).all()\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**. Given the squared distances, return the within-cluster sum of squares.\n",
    "\n",
    "In particular, your function should have the signature,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ```python \n",
    "def WCSS(S): \n",
    "    ...\n",
    "```     \n",
    "\n",
    "where S is an array of distances as might be computed from Exercise 2.\n",
    "\n",
    "For example, suppose S is defined as follows:\n",
    "> ~~~python\n",
    "S = np.array([[0.3, 0.2],\n",
    "              [0.1, 0.5],\n",
    "              [0.4, 0.2]])\n",
    "~~~\n",
    "\n",
    "Then WCSS(S) == 0.2 + 0.1 + 0.2 == 0.5.\n",
    "> Hint: See [numpy.amin](https://docs.scipy.org/doc/numpy/reference/generated/numpy.amin.html#numpy.amin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WCSS(S):\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "# Quick test:\n",
    "print(\"S ==\\n\", S_test1)\n",
    "WCSS_test1 = WCSS(S_test1)\n",
    "print(\"\\nWCSS(S) ==\", WCSS(S_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `WCSS_test`\n",
    "\n",
    "assert np.abs(WCSS_test1 - 0.5) <= 3.0*np.finfo(float).eps, \"WCSS(S_test1) should be close to 0.5, not {}\".format(WCSS_test1)\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, here is a function to check whether the centers have \"moved,\" given two instances of the center values. It accounts for the fact that the order of centers may have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_converged(old_centers, centers):\n",
    "    return set([tuple(x) for x in old_centers]) == set([tuple(x) for x in centers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**. Put all of the preceding building blocks together to implement $k$-means algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, k,\n",
    "           starting_centers=None,\n",
    "           max_steps=np.inf):\n",
    "    \n",
    "    if starting_centers is None:\n",
    "        centers = init_centers(X, k)\n",
    "    else:\n",
    "        centers = starting_centers\n",
    "        \n",
    "    converged = False\n",
    "    labels = np.zeros(len(X))\n",
    "    i = 1\n",
    "    while (not converged) and (i <= max_steps):\n",
    "        old_centers = centers\n",
    "        ### BEGIN SOLUTION\n",
    "\n",
    "        ### END SOLUTION\n",
    "        print (\"iteration\", i, \"WCSS = \", WCSS (S))\n",
    "        i += 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = kmeans(points, k, starting_centers=points[[0, 187], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell: `kmeans_test`\n",
    "\n",
    "df['clustering'] = clustering\n",
    "centers = update_centers(points, clustering)\n",
    "make_scatter_plot(df, hue='clustering', centers=centers)\n",
    "\n",
    "n_matches = count_matches(df['label'], df['clustering'])\n",
    "print(n_matches,\n",
    "      \"matches out of\",\n",
    "      len(df), \"possible\",\n",
    "      \"(~ {:.1f}%)\".format(100.0 * n_matches / len(df)))\n",
    "\n",
    "assert n_matches >= 320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying k-means to an image.** In this section of the notebook, you will apply k-means to an image, for the purpose of doing a \"stylized recoloring\" of it. (You can view this example as a primitive form of [artistic style transfer](http://genekogan.com/works/style-transfer/), which state-of-the-art methods today [accomplish using neural networks](https://medium.com/artists-and-machine-intelligence/neural-artistic-style-transfer-a-comprehensive-look-f54d8649c199).)\n",
    "\n",
    "In particlar, let's take an input image and cluster pixels based on the similarity of their colors. Maybe it can become the basis of your own Instagram filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "def read_img(path):\n",
    "    \"\"\"\n",
    "    Read image and store it as an array, given the image path. \n",
    "    Returns the 3 dimensional image array.\n",
    "    \"\"\"\n",
    "    img = Image.open(path)\n",
    "    img_arr = np.array(img, dtype='int32')\n",
    "    img.close()\n",
    "    return img_arr\n",
    "\n",
    "def display_image(arr):\n",
    "    \"\"\"\n",
    "    display the image\n",
    "    input : 3 dimensional array\n",
    "    \"\"\"\n",
    "    arr = arr.astype(dtype='uint8')\n",
    "    img = Image.fromarray(arr, 'RGB')\n",
    "    imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = read_img(img)\n",
    "display_image(img_arr)\n",
    "print(\"Shape of the matrix obtained by reading the image\")\n",
    "print(img_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the image is stored as a \"3-D\" matrix. It is important to understand how matrices help to store a image. Each pixel corresponds to a intensity value for Red, Green and Blue. If you note the properties of the image, its resolution is 620 x 412. The image width is 620 pixels and height is 412 pixels, and each pixel has three values - R, G, B. This makes it a 412 x 620 x 3 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**. Write some code to reshape the matrix into \"img_reshaped\" by transforming \"img_arr\" from a \"3-D\" matrix to a flattened \"2-D\" matrix which has 3 columns corresponding to the RGB values for each pixel. In this form, the flattened matrix must contain all pixels and their corresponding RGB intensity values. The numpy reshape function may be of help here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell - 'reshape_test'\n",
    "r, c, l = img_arr.shape\n",
    "# The reshaped image is a flattened '2-dimensional' matrix\n",
    "assert len(img_reshaped.shape) == 2\n",
    "r_reshaped, c_reshaped = img_reshaped.shape\n",
    "assert r * c * l == r_reshaped * c_reshaped\n",
    "assert c_reshaped == 3\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**. Now use the k-means function that you wrote above to divide the image in 3 clusters. The result would be a vector named labels, which assigns the label to each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell - 'labels'\n",
    "assert len(labels) == r_reshaped\n",
    "assert set(labels) == {0, 1, 2}\n",
    "print(\"\\nPassed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**. Write code to calculate the mean of each cluster and store it in a dictionary, named centers, as label:array(cluster_center). For 3 clusters, the dictionary should have three keys as the labels and their corresponding cluster centers as values, i.e. {0:array(center0), 1: array(center1), 2:array(center2)}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have written code to generate a matrix \"img_clustered\" of the same dimensions as img_reshaped, where each pixel is replaced by the cluster center to which it belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_clustered = np.array([centers[i] for i in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display the clustered image and see how kmeans works on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c, l = img_arr.shape\n",
    "img_disp = np.reshape(img_clustered, (r, c, l), order=\"C\")\n",
    "display_image(img_disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visually inspect the original image and the clustered image to get a sense of what kmeans is doing here. You can also try to vary the number of clusters to see how the output image changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Built-in $k$-means**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding exercises walked you through how to implement $k$-means, but as you might have imagined, there are existing implementations as well! The following shows you how to use Sklearn's implementation, which should yield similar results. If you are asked to use $k$-means in a future, you can use this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the cluster model using sklearn KMeans\n",
    "\n",
    "k = 5\n",
    "kmeans_sklearn = KMeans(k)\n",
    "kmeans_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/Clustering the data point\n",
    "\n",
    "img_reshaped_sklearn = kmeans_sklearn.fit(img_reshaped)\n",
    "label_sklearn = img_reshaped_sklearn.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating Image from a given cluster\n",
    "\n",
    "ind = np.column_stack((img_reshaped, label_sklearn))\n",
    "\n",
    "centers = {}\n",
    "for i in set(label_sklearn):\n",
    "    c = ind[ind[:,3] == i].mean(axis=0)\n",
    "    centers[i] = c[:3]\n",
    "    \n",
    "img_clustered_sklearn = np.array([centers[i] for i in label_sklearn])\n",
    "\n",
    "r, c, l = img_arr.shape\n",
    "img_disp = np.reshape(img_clustered_sklearn, (r, c, l), order=\"C\")\n",
    "display_image(img_disp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
